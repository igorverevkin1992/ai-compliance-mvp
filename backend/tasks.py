import os
import json
import re
import subprocess
import asyncio
import time
import random
import google.generativeai as genai
from sqlalchemy import text

from celery_app import app
from prompts.instructions import SYSTEM_PROMPT_TEMPLATE
from shazam_helper import recognize_music
from database import SessionLocal, init_db

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

def clean_json_text(text: str) -> str:
    text = re.sub(r"^```json\s*", "", text, flags=re.MULTILINE)
    text = re.sub(r"^```\s*", "", text, flags=re.MULTILINE)
    text = re.sub(r"```$", "", text, flags=re.MULTILINE)
    return text.strip()

def compress_media(input_path: str) -> tuple[str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–ø—É—Ç—å_–∫_—Å–∂–∞—Ç–æ–º—É_—Ñ–∞–π–ª—É, mime_type)
    –ï—Å–ª–∏ —ç—Ç–æ –≤–∏–¥–µ–æ - —Å–∂–∏–º–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –∫–∞–¥—Ä–∞, –Ω–æ –û–°–¢–ê–í–õ–Ø–ï–¢ –í–ò–î–ï–û.
    –ï—Å–ª–∏ –∞—É–¥–∏–æ - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ –ª–µ–≥–∫–∏–π AAC.
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –≤–∏–¥–µ–æ —ç—Ç–æ –∏–ª–∏ –∞—É–¥–∏–æ, —Å –ø–æ–º–æ—â—å—é ffprobe (–∏–ª–∏ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é)
    ext = input_path.split('.')[-1].lower()
    is_video = ext in ['mp4', 'mov', 'avi', 'mkv', 'webm']
    
    output_filename = f"{os.path.splitext(input_path)[0]}_compressed"
    
    if is_video:
        # –°–∂–∏–º–∞–µ–º –í–ò–î–ï–û:
        # -vf scale=640:-2 : –£–º–µ–Ω—å—à–∞–µ–º —à–∏—Ä–∏–Ω—É –¥–æ 640px (–≤—ã—Å–æ—Ç–∞ –∞–≤—Ç–æ), —á—Ç–æ–±—ã Gemini –≤–∏–¥–µ–ª –∫–∞—Ä—Ç–∏–Ω–∫—É, –Ω–æ —Ñ–∞–π–ª –±—ã–ª –ª–µ–≥–∫–∏–º
        # -crf 28 : –°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (—á–µ–º –≤—ã—à–µ —á–∏—Å–ª–æ, —Ç–µ–º —Ö—É–∂–µ –∫–∞—á–µ—Å—Ç–≤–æ –∏ –º–µ–Ω—å—à–µ –≤–µ—Å)
        # -r 24 : 24 –∫–∞–¥—Ä–∞ –≤ —Å–µ–∫—É–Ω–¥—É
        output_path = f"{output_filename}.mp4"
        command = [
            "ffmpeg", "-y", "-i", input_path,
            "-vf", "scale=640:-2", 
            "-c:v", "libx264", "-crf", "28", "-preset", "faster", "-r", "24",
            "-c:a", "aac", "-ac", "1", "-ar", "16000", # –ó–≤—É–∫ —Ç–æ–∂–µ —Å–∂–∏–º–∞–µ–º
            output_path
        ]
        mime = "video/mp4"
    else:
        # –°–∂–∏–º–∞–µ–º –ê–£–î–ò–û (–∫–∞–∫ —Ä–∞–Ω—å—à–µ):
        output_path = f"{output_filename}.m4a"
        command = [
            "ffmpeg", "-y", "-i", input_path,
            "-vn", "-ac", "1", "-ar", "16000", "-c:a", "aac", 
            output_path
        ]
        mime = "audio/mp4"

    try:
        print(f"üé¨ Starting Compression ({mime}) for {input_path}...")
        subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        if os.path.exists(output_path):
            size_mb = os.path.getsize(output_path) / (1024 * 1024)
            print(f"‚úÖ Compression success: {output_path} ({size_mb:.2f} MB)")
            return output_path, mime
    except Exception as e:
        print(f"‚ö†Ô∏è FFmpeg Error: {e}")
        # –ï—Å–ª–∏ —Å–∂–∞—Ç–∏–µ –Ω–µ –≤—ã—à–ª–æ, –≤–µ—Ä–Ω–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        return input_path, ("video/mp4" if is_video else "audio/mp3")
    
    return input_path, "application/octet-stream"

def upload_to_gemini(path: str, mime_type: str):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å –∂–µ—Å—Ç–∫–∏–º –æ–∂–∏–¥–∞–Ω–∏–µ–º —Å—Ç–∞—Ç—É—Å–∞ ACTIVE"""
    print(f"‚òÅÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞: {path} (Mime: {mime_type})")
    if not os.path.exists(path): return None
    
    try:
        file = genai.upload_file(path, mime_type=mime_type)
        print(f"   –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°—Ç–∞—Ç—É—Å: {file.state.name}")
        
        # –¶–ò–ö–õ –û–ñ–ò–î–ê–ù–ò–Ø –û–ë–†–ê–ë–û–¢–ö–ò
        # –ú—ã –¥–æ–ª–∂–Ω—ã –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –æ–ø—Ä–∞—à–∏–≤–∞—Ç—å —Å–µ—Ä–≤–µ—Ä: "–ì–æ—Ç–æ–≤–æ? –ì–æ—Ç–æ–≤–æ?"
        start_time = time.time()
        while file.state.name == "PROCESSING":
            print(f"‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ ({int(time.time() - start_time)}s)", end="\r")
            time.sleep(2)
            # –í–ê–ñ–ù–û: –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç —Ñ–∞–π–ª–∞ —Å —Å–µ—Ä–≤–µ—Ä–∞
            file = genai.get_file(file.name)
            
            # –¢–∞–π–º–∞—É—Ç 5 –º–∏–Ω—É—Ç
            if time.time() - start_time > 300:
                raise Exception("–¢–∞–π–º –∞—É—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (5 –º–∏–Ω).")

        if file.state.name != "ACTIVE":
            raise Exception(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞. –°—Ç–∞—Ç—É—Å: {file.state.name}")

        print(f"‚úÖ –§–∞–π–ª –≥–æ—Ç–æ–≤: {file.name}")
        return file
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        return None

def get_rag_context(db, profile="ntv"):
    try:
        # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä (–ù–¢–í –∏–ª–∏ YouTube)
        if profile == "youtube":
            pub_query = "YouTube%"
        else:
            pub_query = "–ù–¢–í%"

        # 2. –ü–æ–ª–∏—Ç–∏–∫–∏
        sql = text("""
            SELECT r.req_code, r.summary, r.full_text 
            FROM legal_requirement r
            JOIN legal_doc d ON r.doc_id = d.id
            WHERE d.publisher LIKE :pub
        """)
        
        policies = db.execute(sql, {"pub": pub_query}).fetchall()
        
        # –ó–∞—â–∏—Ç–∞: –µ—Å–ª–∏ –ø–æ–ª–∏—Ç–∏–∫ –Ω–µ—Ç, —Å—Ç–∞–≤–∏–º –∑–∞–≥–ª—É—à–∫—É
        if policies:
            policies_text = "\n".join([f"- [{p.req_code}] {p.summary}: {p.full_text[:300]}..." for p in policies])
        else:
            policies_text = "–ù–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–∏—Ç–∏–∫ –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è. –ò—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ –∑–∞–∫–æ–Ω—ã –†–§."

        # 3. –¢–∞–∫—Å–æ–Ω–æ–º–∏—è (–ö–æ–¥—ã –æ—à–∏–±–æ–∫)
        taxonomy = db.execute(text("SELECT code, title FROM taxonomy_label")).fetchall()
        if taxonomy:
            taxonomy_text = "\n".join([f"- {t.code}: {t.title}" for t in taxonomy])
        else:
            taxonomy_text = "–ö–æ–¥—ã –Ω–∞—Ä—É—à–µ–Ω–∏–π –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –±–∞–∑—É."

        # 4. –ü—Ä–∏–º–µ—Ä—ã (RAG)
        reviews = db.execute(text("""
            SELECT notes FROM human_review 
            WHERE verified_json IS NOT NULL 
            ORDER BY created_at DESC LIMIT 5
        """)).fetchall()
        
        human_examples = "–ù–µ—Ç –ø—Ä–∏–º–µ—Ä–æ–≤."
        if reviews:
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ –∑–∞–º–µ—Ç–∫–∏, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –æ—à–∏–±–æ–∫
            valid_notes = [f"–°–ò–¢–£–ê–¶–ò–Ø: {r.notes}" for r in reviews if r.notes]
            if valid_notes:
                human_examples = "\n\n".join(valid_notes)

        # –£–°–ü–ï–•: –í–æ–∑–≤—Ä–∞—â–∞–µ–º 3 –∑–Ω–∞—á–µ–Ω–∏—è
        return policies_text, taxonomy_text, human_examples

    except Exception as e:
        print(f"‚ö†Ô∏è RAG Context Error: {e}")
        # –û–®–ò–ë–ö–ê: –í–æ–∑–≤—Ä–∞—â–∞–µ–º 3 –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, —á—Ç–æ–±—ã –ø—Ä–æ–≥—Ä–∞–º–º–∞ –ù–ï –£–ü–ê–õ–ê
        return "", "", ""

def save_results_to_db(db, asset_id, result_json, model_name):
    try:
        risk = result_json.get('overall', {}).get('risk_level', 'UNKNOWN')
        conf = result_json.get('overall', {}).get('confidence', 0.0)
        
        run_res = db.execute(text("""
            INSERT INTO agent_run (asset_id, model, output_json, overall_risk, overall_confidence)
            VALUES (:aid, :model_name, :json, :risk, :conf)
            RETURNING id
        """), {
            "aid": asset_id,
            "model_name": model_name,  # <--- –í–û–¢ –≠–¢–û–ì–û –ù–ï –•–í–ê–¢–ê–õ–û
            "json": json.dumps(result_json),
            "risk": risk,
            "conf": conf
        }).fetchone()
        run_id = run_res.id

        evidence_map = {}
        for ev in result_json.get('evidence', []):
            pay = {"text": ev.get('text_quote'), "notes": ev.get('notes')}
            ev_res = db.execute(text("""
                INSERT INTO evidence (asset_id, type, start_ms, end_ms, payload)
                VALUES (:aid, :type, :start, :end, :pay)
                RETURNING id
            """), {
                "aid": asset_id, "type": ev.get('type'), 
                "start": ev.get('start_ms', 0), "end": ev.get('end_ms', 0), 
                "pay": json.dumps(pay)
            }).fetchone()
            evidence_map[ev.get('id')] = ev_res.id

        for lbl in result_json.get('labels', []):
            db_ev_ids = [evidence_map[eid] for eid in lbl.get('evidence_ids', []) if eid in evidence_map]
            db.execute(text("""
                INSERT INTO label_detection (run_id, label_code, severity, confidence, rationale, evidence_ids)
                VALUES (:rid, :code, :sev, :conf, :rat, :evs)
            """), {
                "rid": run_id, "code": lbl.get('code'), "sev": lbl.get('severity'),
                "conf": lbl.get('confidence'), "rat": lbl.get('rationale'),
                "evs": db_ev_ids
            })

        for rec in result_json.get('recommendations', []):
            db.execute(text("""
                INSERT INTO recommendation (run_id, action, priority, params)
                VALUES (:rid, :act, :prio, :par)
            """), {
                "rid": run_id, "act": rec.get('action'), "prio": rec.get('priority'),
                "par": json.dumps(rec.get('params'))
            })
            
        db.commit()
        return run_id
    except Exception as e:
        print(f"‚ö†Ô∏è DB Save Error: {e}")
        return None

# --- MAIN TASK ---

@app.task(bind=True)
def analyze_media_task(self, file_path: str, filename: str, api_key: str, model_name: str, profile: str = "ntv"):
    # ^^^ –î–û–ë–ê–í–ò–õ model_name –í –ê–†–ì–£–ú–ï–ù–¢–´ ^^^
    
    files_cleanup = []
    compressed_path = None
    
    try:
        genai.configure(api_key=api_key)
        
        # –ò–°–ü–û–õ–¨–ó–£–ï–ú –í–´–ë–†–ê–ù–ù–£–Æ –ú–û–î–ï–õ–¨
        print(f"ü§ñ Using Model: {model_name}")
        MODEL_NAME = model_name 

        # 1. –û–ë–†–ê–ë–û–¢–ö–ê (–¢–ï–ü–ï–†–¨ –° –í–ò–î–ï–û!)
        self.update_state(state='PROGRESS', meta={'status': '–°–∂–∞—Ç–∏–µ –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ...'})
        # –§—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –ò mime-type
        compressed_path, mime_type = compress_media(file_path)
        
        target_file = compressed_path if compressed_path else file_path

        # 2. Shazam
        shazam_text = ""
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            res = loop.run_until_complete(recognize_music(target_file))
            loop.close()
            if res: shazam_text = f"SHAZAM IDENTIFICATION: {res}"
        except: pass

        # 3. –ó–∞–≥—Ä—É–∑–∫–∞ (–° –ø–æ–¥—Ä–æ–±–Ω—ã–º –¥–µ–±–∞–≥–æ–º)
        self.update_state(state='PROGRESS', meta={'status': '–û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Google Cloud...'})
        media_f = upload_to_gemini(target_file, mime_type)
        
        if not media_f:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–ª–∏–µ–Ω—Ç—É –ø–æ–¥—Ä–æ–±–Ω—É—é –æ—à–∏–±–∫—É (–æ–Ω–∞ –±—É–¥–µ—Ç –≤ –∫–æ–Ω—Å–æ–ª–∏ –≤–æ—Ä–∫–µ—Ä–∞)
            return {"error": "Upload failed. Check Worker Logs for details."}
            
        files_cleanup.append(media_f)

        # 4. RAG
        db = SessionLocal()
        policies, taxonomy, examples = get_rag_context(db, profile)
        
        prompt = SYSTEM_PROMPT_TEMPLATE.format(
            policies_text=policies,
            taxonomy_text=taxonomy,
            human_examples=examples
        )
        
        visual_instruction = f"–ü–†–û–§–ò–õ–¨ –ü–†–û–í–ï–†–ö–ò: {profile.upper()}. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–º –ø–æ–ª–∏—Ç–∏–∫–∞–º. –í–ê–ñ–ù–û: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –í–ò–î–ï–û–†–Ø–î. –û–±—Ä–∞—â–∞–π –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –º–∏–º–∏–∫—É, –∂–µ—Å—Ç—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥—è—â–µ–≥–æ (–∫–æ–º–µ–¥–∏—è, —Å—Å–æ—Ä–∞, –∏–≥—Ä–∞)."

        content = [prompt, visual_instruction, f"–§–∞–π–ª: {filename}. {shazam_text}", media_f]
        content = [x for x in content if x is not None]

        # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        self.update_state(state='PROGRESS', meta={'status': 'AI –¥—É–º–∞–µ—Ç...'})
        model = genai.GenerativeModel(MODEL_NAME)
        
        response = None
        max_retries = 5
        base_wait = 15
        
        for attempt in range(max_retries):
            try:
                response = model.generate_content(
                    content,
                    generation_config={"response_mime_type": "application/json"},
                    safety_settings=SAFETY_SETTINGS
                )
                break
            except Exception as e:
                if "429" in str(e) or "Quota" in str(e):
                    wait = base_wait * (2 ** attempt) + random.uniform(1, 5)
                    self.update_state(state='PROGRESS', meta={'status': f'–õ–∏–º–∏—Ç Google. –ñ–¥–µ–º {int(wait)}—Å...'})
                    time.sleep(wait)
                else: raise e

        if not response or not response.text: return {"error": "Empty response."}

        # 6. –§–∏–Ω–∏—à
        result_data = json.loads(clean_json_text(response.text))
        
        init_db()
        asset_res = db.execute(text("INSERT INTO media_asset (filename, duration_ms) VALUES (:fn, 0) RETURNING id"), {"fn": filename}).fetchone()
        asset_id = asset_res.id
        
        save_results_to_db(db, asset_id, result_data, MODEL_NAME)
        db.close()
        
        result_data['_asset_id'] = str(asset_id)
        return result_data

    except Exception as e:
        print(f"CRITICAL: {e}")
        return {"error": str(e)}
    finally:
        for f in files_cleanup: 
            try: f.delete() 
            except: pass
        if compressed_path and os.path.exists(compressed_path): 
            os.remove(compressed_path)